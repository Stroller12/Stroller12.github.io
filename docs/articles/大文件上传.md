## 大文件上传

## 1.文件切片

传入文件然后返回文件切片后的 Blob 数组, 不过 Blob 数组不能直接用于计算分片 hash, 还需要将它们转成 ArrayBuffer 数组。

### **1.1切片：**

```javascript
/**
 * 分割文件
 * @param file
 * @param baseSize 默认分块大小为 1MB
 * @private
 */
function sliceFile(file: File, baseSize = 1): Blob[] {
  const chunkSize = baseSize * 1024 * 1024 // KB
  const chunks: Blob[] = []
  let startPos = 0
  while (startPos < file.size) {
    chunks.push(file.slice(startPos, startPos + chunkSize))
    startPos += chunkSize
  }
  return chunks
}

```

### **1.2转化为ArrayBuffer数组**：

```javascript
/**
 * 将 File 转成 ArrayBuffer
 * 注意: Blob 无法直接移交到 Worker 中, 所以需要放到主线程中执行
 * @param chunks
 * @private
 */

async function getArrayBufFromBlobsV2(chunks: Blob[]): Promise<ArrayBuffer[]> {
  return Promise.all(chunks.map(chunk => chunk.arrayBuffer()))
}

```

返回promise.all异步任务

切片过程不会消耗太久时间, 其中主要是 IO 瓶颈

而 Blob[] 转 ArrayBuffer[] 的过程是基于 Promise 的, 这并不会阻塞主线程。`Promise.all` + `map` 实现并行异步转换，比同步循环更快。

**Blob转ArrayBuffer[]有的问题：**

- 如果传递 `Blob` 到 Worker 中转换：
  1️⃣ **结构化克隆**：由于 File 或 Blob 并不是 Worker 中的可 Transfer 对象，复制 `Blob` 元数据会造成结构化克隆，产生额外的CPU性能消耗和内存消耗
  2️⃣ **内存翻倍**：Worker 中读取 `ArrayBuffer` 时会生成新副本
  3️⃣ **大文件风险**：2GB 文件 → 主线程和 Worker 各占 2GB → 总计 4GB，容易触发 OOM

### 1.3前端计算分片Hash

#### 概述

使用文件分片的 Hash 来标识文件分片, 用来判断这个分片是否已经上传过了。

计算文件分片 Hash 是一个 CPU 密集型任务, 直接在主线程中计算 hash 必定会导致 UI 卡死, 考虑**放到 WebWorker 中计算 Hash**

ArrayBuffer 是可 Transfer 的对象, 在主线程与 Worker 线程通信时, 可以通过移交控制权的方式通信, **避免线程通信引起的结构化克隆**

分片之间的 Hash 计算没有关联, 而 WebWorker 可以用来开额外的计算线程, 考虑**基于 WebWorker 实现线程池(WorkerPool)来加速计算分片 Hash**

当文件较大时计算使用分片的 MD5值作为 Hash 计算速度仍然较慢, 但分片的 hash 其实只是为了标识分片, 对于唯一性要求并不高, **考虑在文件较大的场景下使用 CRC32 值作为分片的 Hash**

CRC32的十六进制表示只有8位(MD5有32位), 且 CPU 对计算 CRC32 有硬件加速, 速度会比计算 MD5 快得多。

#### MD5的Worker和CRC32的Worker

##### MD5

```javascript
// md5.worker.ts
/// <reference lib="webworker" />

import { WorkerMessage } from './util/worker-message'
import { WorkerLabelsEnum } from './types/worker-labels.enum'
import SparkMD5 from 'spark-md5'

addEventListener('message', ({ data }: { data: ArrayBuffer }) => {
  const hash = SparkMD5.ArrayBuffer.hash(data)

  postMessage(
    new WorkerMessage(WorkerLabelsEnum.DONE, {
      result: hash,
      chunk: data,
    }),
    [data], // 用于 transfer 的数据, 以避免结构化克隆
  )
})

```

##### CRC32的Worker

```javascript
// crc32.worker.ts
/// <reference lib="webworker" />

import { getCrc, getCrcHex } from '../utils/upload-helper'
import { WorkerMessage } from './util/worker-message'
import { WorkerLabelsEnum } from './types/worker-labels.enum'

addEventListener('message', ({ data }: { data: ArrayBuffer }) => {
  const crc = getCrc(data)
  const hash = getCrcHex(crc)

  postMessage(
    new WorkerMessage(WorkerLabelsEnum.DONE, {
      result: hash,
      chunk: data,
    }),
    [data], // 用于 transfer 的数据, 以避免结构化克隆
  )
})

```

##### WorkerMessage: 用于 Worker 线程向主线程通信

```javascript
// WorkerMessage.ts
import { WorkerLabelsEnum } from '../types/worker-labels.enum'

export class WorkerMessage<T = any> {
  label: WorkerLabelsEnum
  content?: T

  constructor(label: WorkerLabelsEnum, content?: T) {
    this.label = label
    this.content = content
  }
}

```

##### WorkerLabelsEnum: 用于标识 Worker Message 的类型

```typescript
// WorkerLabelsEnum.ts
export enum WorkerLabelsEnum {
  INIT,
  CHUNK,
  DONE,
}

```

|   枚举值    |                          典型场景                           |              数据流向示例              |
| :---------: | :---------------------------------------------------------: | :------------------------------------: |
| **`INIT`**  | **初始化 Worker**，传递配置参数（如文件元数据、算法参数等） |            主线程 → Worker             |
| **`CHUNK`** |  **传输数据分片**（如文件的分片二进制数据）或中间计算结果   | 主线程 → Worker **或** Worker → 主线程 |
| **`DONE`**  |     **任务完成通知**（所有分片处理完毕）或最终结果汇总      |            Worker → 主线程             |

```typescript
// WorkerRep.ts
export interface WorkerRep<T = any> {
  data: WorkerMessage<T>
}

```

#### Worker Pool 的实现

##### WorkerWrapper: 基于 Promise 追踪当前 Worker 的运行状态

```typescript
import { WorkerRep } from './worker-message'
import { WorkerLabelsEnum } from '../types/worker-labels.enum'

export enum StatusEnum {
  RUNNING = 'running',
  WAITING = 'waiting',
}

export class WorkerWrapper {
  worker: Worker
  status: StatusEnum

  constructor(
    worker: Worker,
  ) {
    this.worker = worker
    this.status = StatusEnum.WAITING
  }

 run<T>(param: ArrayBuffer, params: ArrayBuffer[], index: number) {
  this.status = StatusEnum.RUNNING // 标记为忙碌状态
  return new Promise<T>((rs, rj) => {
    // 消息监听逻辑
    this.worker.onmessage = ({ data }: WorkerRep<{ result: string; chunk: ArrayBuffer }>) => {
      const { label, content } = data
      if (label === WorkerLabelsEnum.DONE && content) {
        params[index] = content.chunk // 归还分片所有权
        this.status = StatusEnum.WAITING
        rs(content.result as T)       // 解析 Promise 返回结果
      }
    }
    // 错误处理
    this.worker.onerror = (e) => {
      this.status = StatusEnum.WAITING
      rj(e) // 拒绝 Promise 并传递错误
    }
    // 发送任务数据
    this.worker.postMessage(param, [param]) // 转移 param 的所有权
     /*所有权转移：通过 [param] 将 ArrayBuffer 的 ​所有权​ 移交给 Worker，避免结构化克隆（零拷贝，提升性能）。
​注意事项：转移后，主线程中的 param 将不可用，直到 Worker 通过 postMessage 将所有权归还（代码中通过 params[index] = content.chunk 实现）。*/
  })
}


```

##### WorkerPool: 用于管理 WorkerWrapper, 实现 Worker 复用

核心思路是使用发布订阅模式来订阅当前 正在跑的 Worker 的数量(curRunningCount)

此处使用了 Rxjs 中的 BehaviorSubject, 也可以自己写一个 发布订阅模式来实现

只需要实现两个方法 subscribe() 和 next(), 其中 subscribe 用来订阅, next 用于发布新值

```typescript
import { StatusEnum, WorkerWrapper } from './worker-wrapper'
import { BehaviorSubject } from 'rxjs'

export abstract class WorkerPool {
  pool: WorkerWrapper[] = []
  maxWorkerCount: number
  curRunningCount = new BehaviorSubject(0)
  results: any[] = []

  protected constructor(
    maxWorkers = navigator.hardwareConcurrency || 4,
  ) {
    this.maxWorkerCount = maxWorkers
  }

  exec<T>(params: ArrayBuffer[]) {
    this.results.length = 0
    const workerParams = params.map(
      (param, index) => ({ data: param, index }),
    )

    return new Promise<T[]>((rs) => {
      this.curRunningCount.subscribe(count => {
        if (count < this.maxWorkerCount && workerParams.length !== 0) {
          // 当前能跑的任务数量
          let curTaskCount = this.maxWorkerCount - count
          if (curTaskCount > params.length) {
            curTaskCount = params.length
          }

          // 此时可以用来执行任务的 Worker
          const canUseWorker: WorkerWrapper[] = []
          for (const worker of this.pool) {
            if (worker.status === StatusEnum.WAITING) {
              canUseWorker.push(worker)
              if (canUseWorker.length === curTaskCount) {
                break
              }
            }
          }

          const paramsToRun = workerParams.splice(0, curTaskCount)
          // 更新当前正在跑起来的 worker 数量

          this.curRunningCount.next(this.curRunningCount.value + curTaskCount)
          canUseWorker.forEach((workerApp, index) => {
            const param = paramsToRun[index]
            workerApp.run(param.data, params, param.index)
              .then((res) => {
                this.results[param.index] = res
              })
              .catch((e) => {
                this.results[param.index] = e
              })
              .finally(() => {
                this.curRunningCount.next(this.curRunningCount.value - 1)
              })
          })
        }

        if (this.curRunningCount.value === 0 && workerParams.length === 0) {
          rs(this.results as T[])
        }
      })
    })
  }
}


```

##### WorkerPoolForMd5s: 用于实现使用 Worker Pool 计算所有分片的 MD5 值

```typescript
import { WorkerWrapper } from './util/worker-wrapper'
import { WorkerPool } from './util/worker-pool'

export class WorkerPoolForMd5s extends WorkerPool {
  constructor(maxWorkers: number) {
    super(maxWorkers)
    this.pool = Array.from({ length: this.maxWorkerCount }).map(
      () =>
        new WorkerWrapper(
          new Worker(new URL('./md5-single.worker', import.meta.url)),
        ),
    )
  }
}


```

##### WorkerPoolForCrc32s: 用于实现使用 Worker Pool 计算所有分片的 CRC32 值

```typescript
import { WorkerPool } from './util/worker-pool'
import { WorkerWrapper } from './util/worker-wrapper'

export class WorkerPoolForCrc32s extends WorkerPool {
  constructor(
    maxWorkers = navigator.hardwareConcurrency || 4,
  ) {
    super(maxWorkers)
    this.pool = Array.from({ length: this.maxWorkerCount }).map(
      () =>
        new WorkerWrapper(
          new Worker(new URL('./crc32-single.worker', import.meta.url)),
        ),
    )
  }
}


```

##### 使用 Worker Pool 计算分片的 hash 值

```typescript
export class WorkerService {
  readonly MAX_WORKERS = 8
  md5SingleWorkerPool: WorkerPoolForMd5s | undefined
  crc32SingleWorkerPool: WorkerPoolForCrc32s | undefined

  // 计算所有分片的 MD5
  getMD5ForFiles(chunks: ArrayBuffer[]): stirng[] {
    if (this.md5SingleWorkerPool === undefined) {
      this.md5SingleWorkerPool = new WorkerPoolForMd5s(this.MAX_WORKERS)
    }
    return this.md5SingleWorkerPool.exec<string>(chunks)
  }

  // 计算所有分片的 CRC32
  getCRC32ForFiles(chunks: ArrayBuffer[]): stirng[] {
    if (this.crc32SingleWorkerPool === undefined) {
      this.crc32SingleWorkerPool = new WorkerPoolForCrc32s(this.MAX_WORKERS)
    }
    return this.crc32SingleWorkerPool.exec<string>(chunks)
  }
}

```

## 2.前端计算文件Hash

计算文件的 Hash 用来标识这个文件是否已经上传过了

计算全部文件的 hash 无法采用并行计算的方式, 实测假定用户上传 1.8GB 文件, 仅算文件 MD5 就要消耗 15秒 时间(不包括计算文件分片 hash 的时间)

**使用 MerkleTree(默克尔树) 的树根 hash 作为 文件的 hash** ![0908-1-6.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ae1134cdf6b04eff882763867cce7eaa~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=999&h=463&s=71290&e=png&b=000000)

所以得到默克尔树根的 hash 速度会非常快, 因为并没有直接计算全部文件的 hash, 只是根据全部分片的 hash 进行计算

最后使用 树根的 hash 作为 文件 hash, 这样即实现了标识文件的唯一, 计算速度又非常快

```typescript
import SparkMD5 from 'spark-md5'

// 定义 Merkle 树节点的接口
interface IMerkleNode {
  h: string
  l: IMerkleNode | null
  r: IMerkleNode | null
}

// 定义 Merkle 树的接口
interface IMerkleTree {
  root: IMerkleNode
  leafs: IMerkleNode[]
  // 你可以根据需要添加其他属性或方法，例如校验、添加和生成树等功能
}

// Merkle 树节点的类实现
class MerkleNode implements IMerkleNode {
  h: string
  l: IMerkleNode | null
  r: IMerkleNode | null

  constructor(hash: string, left: IMerkleNode | null = null, right: IMerkleNode | null = null) {
    this.h = hash
    this.l = left
    this.r = right
  }
}

// Merkle 树的类实现
export class MerkleTree implements IMerkleTree {
  root: IMerkleNode
  leafs: IMerkleNode[]

  constructor(hashList: string[])
  constructor(leafNodes: IMerkleNode[])
  constructor(nodes: string[] | IMerkleNode[]) {
    if (nodes.length === 0) {
      throw new Error('Empty Nodes')
    }
    if (typeof nodes[0] === 'string') {
      this.leafs = nodes.map((node) => new MerkleNode(node as string))
    } else {
      this.leafs = nodes as IMerkleNode[]
    }
    this.root = this.buildTree()
  }

  getRootHash() {
    return this.root.h
  }

  buildTree(): IMerkleNode {
    // 实现构建 Merkle 树的逻辑。根据叶子节点创建父节点，一直到根节点。
    let currentLevelNodes = this.leafs
    while (currentLevelNodes.length > 1) {
      const parentNodes: IMerkleNode[] = []
      for (let i = 0; i < currentLevelNodes.length; i += 2) {
        const left = currentLevelNodes[i]
        const right = i + 1 < currentLevelNodes.length ? currentLevelNodes[i + 1] : null
        // 具体的哈希计算方法
        const parentHash = this.calculateHash(left, right)
        parentNodes.push(new MerkleNode(parentHash, left, right))
      }
      currentLevelNodes = parentNodes
    }

    return currentLevelNodes[0] // 返回根节点
  }

  // 序列化 Merkle 树
  serialize(): string {
    const serializeNode = (node: IMerkleNode | null): any => {
      if (node === null) {
        return null
      }
      return {
        h: node.h,
        l: serializeNode(node.l),
        r: serializeNode(node.r),
      }
    }

    const serializedRoot = serializeNode(this.root)
    return JSON.stringify(serializedRoot)
  }

  // 反序列化 Merkle 树
  static deserialize(serializedTree: string): MerkleTree {
    const parsedData = JSON.parse(serializedTree)

    const deserializeNode = (data: any): IMerkleNode | null => {
      if (data === null) {
        return null
      }
      return new MerkleNode(data.h, deserializeNode(data.l), deserializeNode(data.r))
    }

    const root = deserializeNode(parsedData)
    if (!root) {
      throw new Error('Invalid serialized tree data')
    }

    // 创建一个包含所有叶子节点的数组，这是为了与 MerkleTree 的构造函数兼容
    // 没有保存这些叶子节点的序列化版本，所以这里需要一些额外的逻辑来处理
    // 如果你需要将整个树的所有节点存储为序列化版本，那么可能需要修改这部分逻辑
    const extractLeafNodes = (node: IMerkleNode): IMerkleNode[] => {
      if (node.l === null && node.r === null) {
        return [node]
      }
      return [
        ...(node.l ? extractLeafNodes(node.l) : []),
        ...(node.r ? extractLeafNodes(node.r) : []),
      ]
    }
    const leafNodes = extractLeafNodes(root)

    return new MerkleTree(leafNodes)
  }

  private calculateHash(left: IMerkleNode, right: IMerkleNode | null): string {
    return right ? SparkMD5.hash(left.h + right.h) : left.h
  }
}


```

##### **使用 MerkleTree 树根的 Hash 作为文件 Hash**

```typescript
// chunksHash 为所有文件分片的 hash 数组
const merkleTree = new MerkleTree(chunksHash)
const fileHash = merkleTree.getRootHash()

```

### 文件分片的并发上传

多个文件分片可以同时上传到后端, 但不能使用 Promise.all() 直接将所有分片一起传到后端,

当文件分片数量较多时, 会导致同时开启的 HTTP 链接过多

**使用一个 PromisePool 来控制同时处于 pending 状态的 Promise 的数量**

使用 Promise.all() 只是用来收集 Promise 数组的执行结果, 它并不能用来控制同时处于 Pending 状态 Promise 的数量, 而 Promise 一旦创建了就会立即执行其中 new Promise() 中的同步代码(即发送网络请求),

所以需要创建 Promise 这个过程用函数包起来, 以实现当需要的时候再去执行

即函数调用的时候才会创建这个 Promise。

实现思路同 Worker Pool

接收一个 `() => Promise<any>` 数组作为任务

这段代码实现了一个 **异步任务并发控制池（Promise Pool）**，核心目标是 **限制同时运行的异步任务数量**，避免资源过载。以下是对代码的逐层解析：

```typescript
import { BehaviorSubject } from 'rxjs'

type AsyncFunction = () => Promise<any>

export class PromisePool {
  private readonly queue: { fn: AsyncFunction, index: number }[] = []
  private readonly maxConcurrentTasks: number
  private results: any[] = []

  curRunningCount = new BehaviorSubject(0)

  constructor(
    functions: AsyncFunction[],
    maxConcurrentTasks: number = navigator.hardwareConcurrency || 8,
  ) {
    this.queue = functions.map((fn, index) => ({ fn, index }))
    this.maxConcurrentTasks = maxConcurrentTasks
  }

  exec<T>() {
    return new Promise<T[]>((rs) => {
      this.curRunningCount.subscribe((count) => {
        if (count < this.maxConcurrentTasks && this.queue.length !== 0) {
          // 当前需要跑的任务数量
          let curTaskCount = this.maxConcurrentTasks - count
          if (curTaskCount > this.queue.length) {
            curTaskCount = this.queue.length
          }
          // 当前要跑的任务
          const tasks = this.queue.splice(0, curTaskCount)
          this.curRunningCount.next(this.curRunningCount.value + curTaskCount)
          // 执行任务
          tasks.forEach((taskWrap) => {
            const { fn, index } = taskWrap
            fn().then((result) => {
              this.results[index] = result
            }).catch((error) => {
              this.results[index] = error
            }).finally(() =>
              this.curRunningCount.next(this.curRunningCount.value - 1)
            )
          })
        }

        if (this.curRunningCount.value === 0 && this.queue.length === 0) {
          rs(this.results as T[])
        }
      })
    })
  }
}


```

##### 使用实例

```typescript
async testPromisePool() {
  const arr = [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ]
  const asyncFns = arr.map(
    (num) => async () => {
      await new Promise<number>((rs) => {
        console.log('跑起来了: ' + num)
        setTimeout(() => {
          rs(num * 2)
        }, 100)
      })

      return new Promise((rs) => {
        setTimeout(() => {
          rs('结果: ' + num * 10)
        }, 2000)
      })
    },
  )

  const pool = new PromisePool(asyncFns, 4)
  pool.exec().then((res) => {
    console.log(res)
  })
}

```

可以看见同时处于 跑起来了状态的 Promise 只有 4 个

## 基于实际上传进度的进度计算

## 整体实现

```
interface IMetaData {
  size: number,
  lastModified: number,
  type: string
}

export class MinioUploaderService {
  // 用于追踪当前的上传阶段
  uploadStatus = new BehaviorSubject<string>('Please select a file.')

  constructor(private uploadApiSvc: UploadApiService) {}

  async doUpload(
    file: File,
    chunkSize: number,
    cb: (progress: number) => void,
  ) {
    // 分片数量小于 borderCount 用 MD5, 否则用 CRC32 算 Hash
    const BORDER_COUNT = 100

    // 文件大小
    const fileSize = file.size / 1000

    // 文件元数据
    const metadata: IMetaData = {
      size: file.size,
      lastModified: file.lastModified,
      type: file.type,
    }

    // 文件分片
    this.uploadStatus.next('Parsing file ...')
    const chunksBlob = sliceFile(file, chunkSize)
    const chunksBuf = await getArrayBufFromBlobsV2(chunksBlob)

    // 按文件分片数量执行不同 Hash 策略
    let chunksHash: string[] = []
    if (chunksBuf.length === 1) {
      chunksHash = [getMD5FromArrayBuffer(chunksBuf[0])]
    } else if (chunksBuf.length <= BORDER_COUNT) {
      chunksHash = await this.workerSvc.getMD5ForFiles(chunksBuf)
    } else {
      chunksHash = await this.workerSvc.getCRC32ForFiles(chunksBuf)
    }
    const merkleTree = new MerkleTree(chunksHash)
    const fileHash = merkleTree.getRootHash()

    // 检查文件是否已经上传过
    this.uploadStatus.next('Checking file if exist ...')
    const { data: existUrl } = await this.uploadApiSvc.checkFileIfExist(fileHash, fileSize)
    if (existUrl) {
      this.uploadStatus.next('Completed.')
      return existUrl
    }
    
    // 查询需要上传的分片
    this.uploadStatus.next('Get the chunks that need to be uploaded ...')
    const { data: _chunksNeedUpload } = await this.uploadApiSvc.getExistChunks(
      fileHash,
      chunksHash,
    )

    // 完整的上传参数
    this.uploadStatus.next('Building upload params ...')
    const paramsMap = new Map<string, FormData>()
    chunksBlob.forEach((chunk, index) => {
      const data = new FormData()
      data.append('files', chunk)
      data.set('name', file.name)
      data.set('index', index.toString())
      data.set('fileHash', fileHash)
      data.set('chunkHash', chunksHash[index])
      paramsMap.set(chunksHash[index], data)
    })

    // 获取实际需要上传的分片
    const params = _chunksNeedUpload.map((chunkHash) => paramsMap.get(chunkHash)!)
    this.uploadStatus.next('Uploading ...')

    // 基于实时上传进度的进度
    const total = file.size
    const currentProgressList: number[] = []
    const intervalId = setInterval(() => {
      const current = currentProgressList.reduce((acc, cur) => acc + cur, 0)
      cb(Math.ceil((current / total) * 100))
    }, 150)

    await new PromisePool(params.map((param, index) => () =>
      this.uploadApiSvc.uploadChunks(param, (current) => {
        currentProgressList[index] = current
      })
    )).exec()
    clearInterval(intervalId)
    cb(100)

    // 获取校验失败的分块并尝试重新上传
    this.uploadStatus.next('Verify uploaded chunks ...')
    const { data: brokenChunksList } = await this.uploadApiSvc.verifyChunks2(fileHash, chunksHash)
    if (brokenChunksList.length !== 0) {
      console.log('brokenChunksList: ', brokenChunksList)
      return ''
    }

    // 合并分片
    this.uploadStatus.next('Merging chunks ...')
    const { data: url } = await this.uploadApiSvc.mergeChunks(fileHash, file.name, fileSize, metadata)
    this.uploadStatus.next('Completed.')
    return url
  }
}

```

